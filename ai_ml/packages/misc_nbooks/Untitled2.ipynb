{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e5abc9e-69ce-40aa-8fcc-000d828db31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import yfinance as yf\n",
    "import streamlit as st\n",
    "import datetime \n",
    "import pandas as pd\n",
    "import cufflinks as cf\n",
    "from plotly.offline import iplot\n",
    "\n",
    "data_path = r'C:\\Users\\pthon\\anaconda3\\envs\\pyfin_env\\data'\n",
    "all_symbols_wiki = data_path + \"\\\\all_symbols_wiki.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3af0bff-d952-4667-a001-3ebb2f72fbf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.27.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-07 17:47:09.844 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\pthon\\anaconda3\\envs\\ta_env\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    },
    {
     "ename": "InternalHashError",
     "evalue": "module '__main__' has no attribute '__file__'\n\nWhile caching the body of `get_sp500_components()`, Streamlit encountered an\nobject of type `builtins.function`, which it does not know how to hash.\n\n**In this specific case, it's very likely you found a Streamlit bug so please\n[file a bug report here.]\n(https://github.com/streamlit/streamlit/issues/new/choose)**\n\nIn the meantime, you can try bypassing this error by registering a custom\nhash function via the `hash_funcs` keyword in @st.cache(). For example:\n\n```\n@st.cache(hash_funcs={builtins.function: my_hash_func})\ndef my_func(...):\n    ...\n```\n\nIf you don't know where the object of type `builtins.function` is coming\nfrom, try looking at the hash chain below for an object that you do recognize,\nthen pass that to `hash_funcs` instead:\n\n```\nObject of type builtins.function: <function get_sp500_components at 0x000001CEFA57FE20>\n```\n\nPlease see the `hash_funcs` [documentation](https://docs.streamlit.io/library/advanced-features/caching#the-hash_funcs-parameter)\nfor more details.\n            ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mC:\\Users\\pthon\\anaconda3\\envs\\ta_env\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:361\u001b[0m, in \u001b[0;36m_CodeHasher.to_bytes\u001b[1;34m(self, obj, context)\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;66;03m# Hash the input\u001b[39;00m\n\u001b[1;32m--> 361\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (tname, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;66;03m# Hmmm... It's possible that the size calculation is wrong. When we\u001b[39;00m\n\u001b[0;32m    364\u001b[0m     \u001b[38;5;66;03m# call to_bytes inside _to_bytes things get double-counted.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Users\\pthon\\anaconda3\\envs\\ta_env\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:622\u001b[0m, in \u001b[0;36m_CodeHasher._to_bytes\u001b[1;34m(self, obj, context)\u001b[0m\n\u001b[0;32m    621\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m code \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_file_should_be_hashed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mco_filename\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    623\u001b[0m     context \u001b[38;5;241m=\u001b[39m _get_context(obj)\n",
      "File \u001b[1;32mC:\\Users\\pthon\\anaconda3\\envs\\ta_env\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:403\u001b[0m, in \u001b[0;36m_CodeHasher._file_should_be_hashed\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m file_util\u001b[38;5;241m.\u001b[39mfile_is_in_folder_glob(\n\u001b[1;32m--> 403\u001b[0m     filepath, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_main_script_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    404\u001b[0m ) \u001b[38;5;129;01mor\u001b[39;00m file_util\u001b[38;5;241m.\u001b[39mfile_in_pythonpath(filepath)\n",
      "File \u001b[1;32mC:\\Users\\pthon\\anaconda3\\envs\\ta_env\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:709\u001b[0m, in \u001b[0;36m_CodeHasher._get_main_script_directory\u001b[1;34m()\u001b[0m\n\u001b[0;32m    707\u001b[0m \u001b[38;5;66;03m# This works because we set __main__.__file__ to the\u001b[39;00m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;66;03m# script path in ScriptRunner.\u001b[39;00m\n\u001b[1;32m--> 709\u001b[0m abs_main_path \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(\u001b[43m__main__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__file__\u001b[39;49m)\u001b[38;5;241m.\u001b[39mresolve()\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(abs_main_path\u001b[38;5;241m.\u001b[39mparent)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module '__main__' has no attribute '__file__'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInternalHashError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 28\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# sidebar\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m## inputs for downloading data\u001b[39;00m\n\u001b[0;32m     26\u001b[0m st\u001b[38;5;241m.\u001b[39msidebar\u001b[38;5;241m.\u001b[39mheader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStock Parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m available_tickers, tickers_companies_dict \u001b[38;5;241m=\u001b[39m \u001b[43mget_sp500_components\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m ticker \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39msidebar\u001b[38;5;241m.\u001b[39mselectbox(\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTicker\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m     32\u001b[0m     available_tickers, \n\u001b[0;32m     33\u001b[0m     format_func\u001b[38;5;241m=\u001b[39mtickers_companies_dict\u001b[38;5;241m.\u001b[39mget\n\u001b[0;32m     34\u001b[0m )\n\u001b[0;32m     35\u001b[0m start_date \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39msidebar\u001b[38;5;241m.\u001b[39mdate_input(\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart date\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m     37\u001b[0m     datetime\u001b[38;5;241m.\u001b[39mdate(\u001b[38;5;241m2019\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     38\u001b[0m )\n",
      "File \u001b[1;32mC:\\Users\\pthon\\anaconda3\\envs\\ta_env\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\caching.py:716\u001b[0m, in \u001b[0;36mcache.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m show_spinner:\n\u001b[0;32m    715\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m spinner(message, cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 716\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_or_create_cached_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    718\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_or_create_cached_value()\n",
      "File \u001b[1;32mC:\\Users\\pthon\\anaconda3\\envs\\ta_env\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\caching.py:638\u001b[0m, in \u001b[0;36mcache.<locals>.wrapped_func.<locals>.get_or_create_cached_value\u001b[1;34m()\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mnonlocal\u001b[39;00m cache_key\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;66;03m# Delay generating the cache key until the first call.\u001b[39;00m\n\u001b[0;32m    634\u001b[0m     \u001b[38;5;66;03m# This way we can see values of globals, including functions\u001b[39;00m\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;66;03m# defined after this one.\u001b[39;00m\n\u001b[0;32m    636\u001b[0m     \u001b[38;5;66;03m# If we generated the key earlier we would only hash those\u001b[39;00m\n\u001b[0;32m    637\u001b[0m     \u001b[38;5;66;03m# globals by name, and miss changes in their code or value.\u001b[39;00m\n\u001b[1;32m--> 638\u001b[0m     cache_key \u001b[38;5;241m=\u001b[39m \u001b[43m_hash_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnon_optional_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhash_funcs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;66;03m# First, get the cache that's attached to this function.\u001b[39;00m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;66;03m# This cache's key is generated (above) from the function's code.\u001b[39;00m\n\u001b[0;32m    642\u001b[0m mem_cache \u001b[38;5;241m=\u001b[39m _mem_caches\u001b[38;5;241m.\u001b[39mget_cache(cache_key, max_entries, ttl)\n",
      "File \u001b[1;32mC:\\Users\\pthon\\anaconda3\\envs\\ta_env\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\caching.py:768\u001b[0m, in \u001b[0;36m_hash_func\u001b[1;34m(func, hash_funcs)\u001b[0m\n\u001b[0;32m    757\u001b[0m update_hash(\n\u001b[0;32m    758\u001b[0m     (func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m),\n\u001b[0;32m    759\u001b[0m     hasher\u001b[38;5;241m=\u001b[39mfunc_hasher,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    762\u001b[0m     hash_source\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m    763\u001b[0m )\n\u001b[0;32m    765\u001b[0m \u001b[38;5;66;03m# Include the function's body in the hash. We *do* pass hash_funcs here,\u001b[39;00m\n\u001b[0;32m    766\u001b[0m \u001b[38;5;66;03m# because this step will be hashing any objects referenced in the function\u001b[39;00m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;66;03m# body.\u001b[39;00m\n\u001b[1;32m--> 768\u001b[0m \u001b[43mupdate_hash\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    769\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhasher\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_hasher\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhash_funcs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhash_funcs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhash_reason\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHashReason\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCACHING_FUNC_BODY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhash_source\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    774\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    775\u001b[0m cache_key \u001b[38;5;241m=\u001b[39m func_hasher\u001b[38;5;241m.\u001b[39mhexdigest()\n\u001b[0;32m    776\u001b[0m _LOGGER\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmem_cache key for \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m, cache_key\n\u001b[0;32m    778\u001b[0m )\n",
      "File \u001b[1;32mC:\\Users\\pthon\\anaconda3\\envs\\ta_env\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:109\u001b[0m, in \u001b[0;36mupdate_hash\u001b[1;34m(val, hasher, hash_reason, hash_source, context, hash_funcs)\u001b[0m\n\u001b[0;32m    106\u001b[0m hash_stacks\u001b[38;5;241m.\u001b[39mcurrent\u001b[38;5;241m.\u001b[39mhash_source \u001b[38;5;241m=\u001b[39m hash_source\n\u001b[0;32m    108\u001b[0m ch \u001b[38;5;241m=\u001b[39m _CodeHasher(hash_funcs)\n\u001b[1;32m--> 109\u001b[0m \u001b[43mch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhasher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Users\\pthon\\anaconda3\\envs\\ta_env\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:386\u001b[0m, in \u001b[0;36m_CodeHasher.update\u001b[1;34m(self, hasher, obj, context)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, hasher, obj: Any, context: Optional[Context] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Update the provided hasher with the hash of an object.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 386\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m     hasher\u001b[38;5;241m.\u001b[39mupdate(b)\n",
      "File \u001b[1;32mC:\\Users\\pthon\\anaconda3\\envs\\ta_env\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:375\u001b[0m, in \u001b[0;36m_CodeHasher.to_bytes\u001b[1;34m(self, obj, context)\u001b[0m\n\u001b[0;32m    372\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m--> 375\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InternalHashError(ex, obj)\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;66;03m# In case an UnhashableTypeError (or other) error is thrown, clean up the\u001b[39;00m\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;66;03m# stack so we don't get false positives in future hashing calls\u001b[39;00m\n\u001b[0;32m    380\u001b[0m     hash_stacks\u001b[38;5;241m.\u001b[39mcurrent\u001b[38;5;241m.\u001b[39mpop()\n",
      "File \u001b[1;32mC:\\Users\\pthon\\anaconda3\\envs\\ta_env\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:361\u001b[0m, in \u001b[0;36m_CodeHasher.to_bytes\u001b[1;34m(self, obj, context)\u001b[0m\n\u001b[0;32m    357\u001b[0m hash_stacks\u001b[38;5;241m.\u001b[39mcurrent\u001b[38;5;241m.\u001b[39mpush(obj)\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;66;03m# Hash the input\u001b[39;00m\n\u001b[1;32m--> 361\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (tname, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;66;03m# Hmmm... It's possible that the size calculation is wrong. When we\u001b[39;00m\n\u001b[0;32m    364\u001b[0m     \u001b[38;5;66;03m# call to_bytes inside _to_bytes things get double-counted.\u001b[39;00m\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mgetsizeof(b)\n",
      "File \u001b[1;32mC:\\Users\\pthon\\anaconda3\\envs\\ta_env\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:622\u001b[0m, in \u001b[0;36m_CodeHasher._to_bytes\u001b[1;34m(self, obj, context)\u001b[0m\n\u001b[0;32m    620\u001b[0m code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__code__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    621\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m code \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_file_should_be_hashed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mco_filename\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    623\u001b[0m     context \u001b[38;5;241m=\u001b[39m _get_context(obj)\n\u001b[0;32m    624\u001b[0m     defaults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__defaults__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Users\\pthon\\anaconda3\\envs\\ta_env\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:403\u001b[0m, in \u001b[0;36m_CodeHasher._file_should_be_hashed\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_is_blacklisted:\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m file_util\u001b[38;5;241m.\u001b[39mfile_is_in_folder_glob(\n\u001b[1;32m--> 403\u001b[0m     filepath, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_main_script_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    404\u001b[0m ) \u001b[38;5;129;01mor\u001b[39;00m file_util\u001b[38;5;241m.\u001b[39mfile_in_pythonpath(filepath)\n",
      "File \u001b[1;32mC:\\Users\\pthon\\anaconda3\\envs\\ta_env\\lib\\site-packages\\streamlit\\runtime\\legacy_caching\\hashing.py:709\u001b[0m, in \u001b[0;36m_CodeHasher._get_main_script_directory\u001b[1;34m()\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01m__main__\u001b[39;00m\n\u001b[0;32m    707\u001b[0m \u001b[38;5;66;03m# This works because we set __main__.__file__ to the\u001b[39;00m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;66;03m# script path in ScriptRunner.\u001b[39;00m\n\u001b[1;32m--> 709\u001b[0m abs_main_path \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(\u001b[43m__main__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__file__\u001b[39;49m)\u001b[38;5;241m.\u001b[39mresolve()\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(abs_main_path\u001b[38;5;241m.\u001b[39mparent)\n",
      "\u001b[1;31mInternalHashError\u001b[0m: module '__main__' has no attribute '__file__'\n\nWhile caching the body of `get_sp500_components()`, Streamlit encountered an\nobject of type `builtins.function`, which it does not know how to hash.\n\n**In this specific case, it's very likely you found a Streamlit bug so please\n[file a bug report here.]\n(https://github.com/streamlit/streamlit/issues/new/choose)**\n\nIn the meantime, you can try bypassing this error by registering a custom\nhash function via the `hash_funcs` keyword in @st.cache(). For example:\n\n```\n@st.cache(hash_funcs={builtins.function: my_hash_func})\ndef my_func(...):\n    ...\n```\n\nIf you don't know where the object of type `builtins.function` is coming\nfrom, try looking at the hash chain below for an object that you do recognize,\nthen pass that to `hash_funcs` instead:\n\n```\nObject of type builtins.function: <function get_sp500_components at 0x000001CEFA57FE20>\n```\n\nPlease see the `hash_funcs` [documentation](https://docs.streamlit.io/library/advanced-features/caching#the-hash_funcs-parameter)\nfor more details.\n            "
     ]
    }
   ],
   "source": [
    "## set offline mode for cufflinks\n",
    "cf.go_offline()\n",
    "\n",
    "# data functions\n",
    "@st.cache\n",
    "def get_sp500_components():\n",
    "    df = pd.read_html(\"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\")\n",
    "    df = df[0]\n",
    "    tickers = df[\"Symbol\"].to_list()\n",
    "    tickers_companies_dict = dict(\n",
    "        zip(df[\"Symbol\"], df[\"Security\"])\n",
    "    )\n",
    "    return tickers, tickers_companies_dict\n",
    "\n",
    "@st.cache\n",
    "def load_data(symbol, start, end):\n",
    "    return yf.download(symbol, start, end)\n",
    "\n",
    "@st.cache\n",
    "def convert_df_to_csv(df):\n",
    "    return df.to_csv().encode(\"utf-8\")\n",
    "\n",
    "# sidebar\n",
    "\n",
    "## inputs for downloading data\n",
    "st.sidebar.header(\"Stock Parameters\")\n",
    "\n",
    "available_tickers, tickers_companies_dict = get_sp500_components()\n",
    "\n",
    "ticker = st.sidebar.selectbox(\n",
    "    \"Ticker\", \n",
    "    available_tickers, \n",
    "    format_func=tickers_companies_dict.get\n",
    ")\n",
    "start_date = st.sidebar.date_input(\n",
    "    \"Start date\", \n",
    "    datetime.date(2019, 1, 1)\n",
    ")\n",
    "end_date = st.sidebar.date_input(\n",
    "    \"End date\", \n",
    "    datetime.date.today()\n",
    ")\n",
    "\n",
    "if start_date > end_date:\n",
    "    st.sidebar.error(\"The end date must fall after the start date\")\n",
    "\n",
    "## inputs for technical analysis\n",
    "st.sidebar.header(\"Technical Analysis Parameters\")\n",
    "\n",
    "volume_flag = st.sidebar.checkbox(label=\"Add volume\")\n",
    "\n",
    "exp_sma = st.sidebar.expander(\"SMA\")\n",
    "sma_flag = exp_sma.checkbox(label=\"Add SMA\")\n",
    "sma_periods= exp_sma.number_input(\n",
    "    label=\"SMA Periods\", \n",
    "    min_value=1, \n",
    "    max_value=50, \n",
    "    value=20, \n",
    "    step=1\n",
    ")\n",
    "\n",
    "exp_bb = st.sidebar.expander(\"Bollinger Bands\")\n",
    "bb_flag = exp_bb.checkbox(label=\"Add Bollinger Bands\")\n",
    "bb_periods= exp_bb.number_input(label=\"BB Periods\", \n",
    "                                min_value=1, max_value=50, \n",
    "                                value=20, step=1)\n",
    "bb_std= exp_bb.number_input(label=\"# of standard deviations\", \n",
    "                            min_value=1, max_value=4, \n",
    "                            value=2, step=1)\n",
    "\n",
    "exp_rsi = st.sidebar.expander(\"Relative Strength Index\")\n",
    "rsi_flag = exp_rsi.checkbox(label=\"Add RSI\")\n",
    "rsi_periods= exp_rsi.number_input(\n",
    "    label=\"RSI Periods\", \n",
    "    min_value=1, \n",
    "    max_value=50, \n",
    "    value=20, \n",
    "    step=1\n",
    ")\n",
    "rsi_upper= exp_rsi.number_input(label=\"RSI Upper\", \n",
    "                                min_value=50, \n",
    "                                max_value=90, value=70, \n",
    "                                step=1)\n",
    "rsi_lower= exp_rsi.number_input(label=\"RSI Lower\", \n",
    "                                min_value=10, \n",
    "                                max_value=50, value=30, \n",
    "                                step=1)\n",
    "\n",
    "# main body\n",
    "\n",
    "st.title(\"A simple web app for technical analysis\")\n",
    "st.write(\"\"\"\n",
    "### User manual\n",
    "* you can select any of the companies that is a component of the S&P index\n",
    "* you can select the time period of your interest\n",
    "* you can download the selected data as a CSV file\n",
    "* you can add the following Technical Indicators to the plot: Simple Moving \n",
    "Average, Bollinger Bands, Relative Strength Index\n",
    "* you can experiment with different parameters of the indicators\n",
    "\"\"\")\n",
    "\n",
    "df = load_data(ticker, start_date, end_date)\n",
    "\n",
    "## data preview part\n",
    "data_exp = st.expander(\"Preview data\")\n",
    "available_cols = df.columns.tolist()\n",
    "columns_to_show = data_exp.multiselect(\n",
    "    \"Columns\", \n",
    "    available_cols, \n",
    "    default=available_cols\n",
    ")\n",
    "data_exp.dataframe(df[columns_to_show])\n",
    "\n",
    "csv_file = convert_df_to_csv(df[columns_to_show])\n",
    "data_exp.download_button(\n",
    "    label=\"Download selected as CSV\",\n",
    "    data=csv_file,\n",
    "    file_name=f\"{ticker}_stock_prices.csv\",\n",
    "    mime=\"text/csv\",\n",
    ")\n",
    "\n",
    "## technical analysis plot\n",
    "title_str = f\"{tickers_companies_dict[ticker]}'s stock price\"\n",
    "qf = cf.QuantFig(df, title=title_str)\n",
    "if volume_flag:\n",
    "    qf.add_volume()\n",
    "if sma_flag:\n",
    "    qf.add_sma(periods=sma_periods)\n",
    "if bb_flag:\n",
    "    qf.add_bollinger_bands(periods=bb_periods,\n",
    "                           boll_std=bb_std)\n",
    "if rsi_flag:\n",
    "    qf.add_rsi(periods=rsi_periods,\n",
    "               rsi_upper=rsi_upper,\n",
    "               rsi_lower=rsi_lower,\n",
    "               showbands=True)\n",
    "\n",
    "fig = qf.iplot(asFigure=True)\n",
    "st.plotly_chart(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af81919a-0b8c-4e7b-b3d6-2b462d5109f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
