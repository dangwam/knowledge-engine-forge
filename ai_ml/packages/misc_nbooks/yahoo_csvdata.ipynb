{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "032426da-627e-49ce-94f1-d6f50a2b78ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extention file -------custom extension file \n",
      "mayank your_path C:\\Users\\MAYANK DANGWAL\\.zipline\\csv\\yahoo_csvdata\n",
      "yahoo_csvdata 2023-12-16 13:13:45.284532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MAYANK DANGWAL\\.zipline\\extension.py:20: UserWarning: Overwriting bundle with name 'yahoo_csvdata'\n",
      "  register(\n"
     ]
    }
   ],
   "source": [
    "!zipline bundles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "902cc5c0-aa13-46d8-9ee5-e76b6868952b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_bundle_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m source_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMAYANK DANGWAL\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.zipline\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcsv\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124myahoo_csvdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mrivn.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Load data from bundle\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m bundle_data \u001b[38;5;241m=\u001b[39m \u001b[43mload_bundle_data\u001b[49m(bundle_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrivn\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Load source data\u001b[39;00m\n\u001b[0;32m     12\u001b[0m source_data \u001b[38;5;241m=\u001b[39m read_csv(source_path)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_bundle_data' is not defined"
     ]
    }
   ],
   "source": [
    "from zipline.data import loader\n",
    "from pandas import read_csv\n",
    "\n",
    "# Define bundle and source data paths\n",
    "bundle_path = r\"C:\\Users\\MAYANK DANGWAL\\.zipline\\data\\yahoo_csvdata\"\n",
    "source_path = r\"C:\\Users\\MAYANK DANGWAL\\.zipline\\csv\\yahoo_csvdata\\rivn.csv\"\n",
    "\n",
    "# Load data from bundle\n",
    "bundle_data = load_bundle_data(bundle_path, \"rivn\")\n",
    "\n",
    "# Load source data\n",
    "source_data = read_csv(source_path)\n",
    "\n",
    "# Print basic information about both datasets\n",
    "print(\"Bundle data:\")\n",
    "print(bundle_data.head())\n",
    "print(f\"\\nNumber of rows: {len(bundle_data)}\")\n",
    "print(f\"\\nData types: {bundle_data.dtypes}\")\n",
    "\n",
    "print(\"Source data:\")\n",
    "print(source_data.head())\n",
    "print(f\"\\nNumber of rows: {len(source_data)}\")\n",
    "print(f\"\\nData types: {source_data.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f0e61a0-b33c-446a-b675-d01fe22a61a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'load_bundle_data' from 'zipline.data.bundles' (C:\\Users\\pthon\\anaconda3\\envs\\ta_env\\lib\\site-packages\\zipline\\data\\bundles\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mzipline\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbundles\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_bundle_data\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_csv\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Define bundle and source data paths\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'load_bundle_data' from 'zipline.data.bundles' (C:\\Users\\pthon\\anaconda3\\envs\\ta_env\\lib\\site-packages\\zipline\\data\\bundles\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from zipline.data.bundles import load_bundle_data\n",
    "from pandas import read_csv\n",
    "\n",
    "# Define bundle and source data paths\n",
    "bundle_path = r\"C:\\Users\\MAYANK DANGWAL\\.zipline\\data\\yahoo_csvdata\"\n",
    "source_path = r\"C:\\Users\\MAYANK DANGWAL\\.zipline\\csv\\yahoo_csvdata\\rivn.csv\"\n",
    "\n",
    "# Load data from bundle\n",
    "bundle_data = load_bundle_data(bundle_path, \"rivn\")\n",
    "\n",
    "# Load source data\n",
    "source_data = read_csv(source_path)\n",
    "\n",
    "# Print basic information about both datasets\n",
    "print(\"Bundle data:\")\n",
    "print(bundle_data.head())\n",
    "print(f\"\\nNumber of rows: {len(bundle_data)}\")\n",
    "print(f\"\\nData types: {bundle_data.dtypes}\")\n",
    "\n",
    "print(\"Source data:\")\n",
    "print(source_data.head())\n",
    "print(f\"\\nNumber of rows: {len(source_data)}\")\n",
    "print(f\"\\nData types: {source_data.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45846196-ae67-46f2-84aa-e2a1598c28e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'load_bundle_data' from 'zipline.data.bundles' (C:\\Users\\pthon\\anaconda3\\envs\\ta_env\\lib\\site-packages\\zipline\\data\\bundles\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mzipline\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbundles\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_bundle_data\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_csv\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Define bundle and source data paths\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'load_bundle_data' from 'zipline.data.bundles' (C:\\Users\\pthon\\anaconda3\\envs\\ta_env\\lib\\site-packages\\zipline\\data\\bundles\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from zipline.data.bundles import load_bundle_data\n",
    "from pandas import read_csv\n",
    "\n",
    "# Define bundle and source data paths\n",
    "bundle_path = r\"C:\\Users\\MAYANK DANGWAL\\.zipline\\data\\yahoo_csvdata\"\n",
    "source_path = r\"C:\\Users\\MAYANK DANGWAL\\.zipline\\csv\\yahoo_csvdata\\rivn.csv\"\n",
    "\n",
    "# Load data from bundle\n",
    "bundle_data = load_bundle_data(bundle_path, \"rivn\")\n",
    "\n",
    "# Load source data\n",
    "source_data = read_csv(source_path)\n",
    "\n",
    "# Print basic information about both datasets\n",
    "print(\"Bundle data:\")\n",
    "print(bundle_data.head())\n",
    "print(f\"\\nNumber of rows: {len(bundle_data)}\")\n",
    "print(f\"\\nData types: {bundle_data.dtypes}\")\n",
    "\n",
    "print(\"Source data:\")\n",
    "print(source_data.head())\n",
    "print(f\"\\nNumber of rows: {len(source_data)}\")\n",
    "print(f\"\\nData types: {source_data.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b739cb8c-6381-48a7-86c9-f21b6c9c7360",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Module for building a complete dataset from local directory with csv files.\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from zipline.utils.calendar_utils import register_calendar_alias\n",
    "from zipline.utils.cli import maybe_show_progress\n",
    "\n",
    "from . import core as bundles\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "handler = logging.StreamHandler()\n",
    "# handler = logging.StreamHandler(sys.stdout, format_string=\" | {record.message}\")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.handlers.append(handler)\n",
    "\n",
    "#def csvdir_equities(tframes=None, csvdir=None):\n",
    "def yahoo_csvdata(tframes=None, csvdir=None):\n",
    "    \"\"\"\n",
    "    Generate an ingest function for custom data bundle\n",
    "    This function can be used in ~/.zipline/extension.py\n",
    "    to register bundle with custom parameters, e.g. with\n",
    "    a custom trading calendar.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tframes: tuple, optional\n",
    "        The data time frames, supported timeframes: 'daily' and 'minute'\n",
    "    csvdir : string, optional, default: CSVDIR environment variable\n",
    "        The path to the directory of this structure:\n",
    "        <directory>/<timeframe1>/<symbol1>.csv\n",
    "        <directory>/<timeframe1>/<symbol2>.csv\n",
    "        <directory>/<timeframe1>/<symbol3>.csv\n",
    "        <directory>/<timeframe2>/<symbol1>.csv\n",
    "        <directory>/<timeframe2>/<symbol2>.csv\n",
    "        <directory>/<timeframe2>/<symbol3>.csv\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ingest : callable\n",
    "        The bundle ingest function\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    This code should be added to ~/.zipline/extension.py\n",
    "    .. code-block:: python\n",
    "       from zipline.data.bundles import csvdir_equities, register\n",
    "       register('custom-csvdir-bundle',\n",
    "                csvdir_equities([\"daily\", \"minute\"],\n",
    "                '/full/path/to/the/csvdir/directory'))\n",
    "    \"\"\"\n",
    "\n",
    "    return yahoo_csvdataBundle(tframes, csvdir).ingest\n",
    "\n",
    "\n",
    "class yahoo_csvdataBundle:\n",
    "    \"\"\"\n",
    "    Wrapper class to call csvdir_bundle with provided\n",
    "    list of time frames and a path to the csvdir directory\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tframes=None, csvdir=None):\n",
    "        self.tframes = tframes\n",
    "        self.csvdir = csvdir\n",
    "\n",
    "    def ingest(\n",
    "        self,\n",
    "        environ,\n",
    "        asset_db_writer,\n",
    "        minute_bar_writer,\n",
    "        daily_bar_writer,\n",
    "        adjustment_writer,\n",
    "        calendar,\n",
    "        start_session,\n",
    "        end_session,\n",
    "        cache,\n",
    "        show_progress,\n",
    "        output_dir,\n",
    "    ):\n",
    "        yahoo_csvdataBundle(\n",
    "            environ,\n",
    "            asset_db_writer,\n",
    "            minute_bar_writer,\n",
    "            daily_bar_writer,\n",
    "            adjustment_writer,\n",
    "            calendar,\n",
    "            start_session,\n",
    "            end_session,\n",
    "            cache,\n",
    "            show_progress,\n",
    "            output_dir,\n",
    "            self.tframes,\n",
    "            self.csvdir,\n",
    "        )\n",
    "\n",
    "\n",
    "@bundles.register(\"yahoo_csvdata\")\n",
    "def yahoo_csvdata_bundle(\n",
    "    environ,\n",
    "    asset_db_writer,\n",
    "    minute_bar_writer,\n",
    "    daily_bar_writer,\n",
    "    adjustment_writer,\n",
    "    calendar,\n",
    "    start_session,\n",
    "    end_session,\n",
    "    cache,\n",
    "    show_progress,\n",
    "    output_dir,\n",
    "    tframes=None,\n",
    "    csvdir=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Build a zipline data bundle from the directory with csv files.\n",
    "    \"\"\"\n",
    "    print(\"mayank csvdir\",csvdir)\n",
    "    if not csvdir:\n",
    "        csvdir = environ.get(\"CSVDIR\")\n",
    "        if not csvdir:\n",
    "            raise ValueError(\"CSVDIR environment variable is not set\")\n",
    "\n",
    "    if not os.path.isdir(csvdir):\n",
    "        raise ValueError(\"%s is not a directory\" % csvdir)\n",
    "\n",
    "    if not tframes:\n",
    "        tframes = set([\"daily\", \"minute\"]).intersection(os.listdir(csvdir))\n",
    "\n",
    "        if not tframes:\n",
    "            raise ValueError(\n",
    "                \"'daily' and 'minute' directories \" \"not found in '%s'\" % csvdir\n",
    "            )\n",
    "\n",
    "    divs_splits = {\n",
    "        \"divs\": pd.DataFrame(\n",
    "            columns=[\n",
    "                \"sid\",\n",
    "                \"amount\",\n",
    "                \"ex_date\",\n",
    "                \"record_date\",\n",
    "                \"declared_date\",\n",
    "                \"pay_date\",\n",
    "            ]\n",
    "        ),\n",
    "        \"splits\": pd.DataFrame(columns=[\"sid\", \"ratio\", \"effective_date\"]),\n",
    "    }\n",
    "    for tframe in tframes:\n",
    "        ddir = os.path.join(csvdir, tframe)\n",
    "\n",
    "        symbols = sorted(\n",
    "            item.split(\".csv\")[0] for item in os.listdir(ddir) if \".csv\" in item\n",
    "        )\n",
    "        if not symbols:\n",
    "            raise ValueError(\"no <symbol>.csv* files found in %s\" % ddir)\n",
    "\n",
    "        dtype = [\n",
    "            (\"start_date\", \"datetime64[ns]\"),\n",
    "            (\"end_date\", \"datetime64[ns]\"),\n",
    "            (\"auto_close_date\", \"datetime64[ns]\"),\n",
    "            (\"symbol\", \"object\"),\n",
    "        ]\n",
    "        metadata = pd.DataFrame(np.empty(len(symbols), dtype=dtype))\n",
    "\n",
    "        if tframe == \"minute\":\n",
    "            writer = minute_bar_writer\n",
    "        else:\n",
    "            writer = daily_bar_writer\n",
    "\n",
    "        writer.write(\n",
    "            _pricing_iter(ddir, symbols, metadata, divs_splits, show_progress),\n",
    "            show_progress=show_progress,\n",
    "        )\n",
    "\n",
    "        # Hardcode the exchange to \"CSVDIR\" for all assets and (elsewhere)\n",
    "        # register \"CSVDIR\" to resolve to the NYSE calendar, because these\n",
    "        # are all equities and thus can use the NYSE calendar.\n",
    "        metadata[\"exchange\"] = \"NYSE\"\n",
    "\n",
    "        asset_db_writer.write(equities=metadata)\n",
    "\n",
    "        divs_splits[\"divs\"][\"sid\"] = divs_splits[\"divs\"][\"sid\"].astype(int)\n",
    "        divs_splits[\"splits\"][\"sid\"] = divs_splits[\"splits\"][\"sid\"].astype(int)\n",
    "        adjustment_writer.write(\n",
    "            splits=divs_splits[\"splits\"], dividends=divs_splits[\"divs\"]\n",
    "        )\n",
    "\n",
    "\n",
    "def _pricing_iter(csvdir, symbols, metadata, divs_splits, show_progress):\n",
    "    with maybe_show_progress(\n",
    "        symbols, show_progress, label=\"Loading custom pricing data: \"\n",
    "    ) as it:\n",
    "        # using scandir instead of listdir can be faster\n",
    "        files = os.scandir(csvdir)\n",
    "        # building a dictionary of filenames\n",
    "        # NOTE: if there are duplicates it will arbitrarily pick the latest found\n",
    "        fnames = {f.name.split(\".\")[0]: f.name for f in files if f.is_file()}\n",
    "\n",
    "        for sid, symbol in enumerate(it):\n",
    "            logger.debug(f\"{symbol}: sid {sid}\")\n",
    "            fname = fnames.get(symbol, None)\n",
    "\n",
    "            if fname is None:\n",
    "                raise ValueError(f\"{symbol}.csv file is not in {csvdir}\")\n",
    "\n",
    "            # NOTE: read_csv can also read compressed csv files\n",
    "            dfr = pd.read_csv(\n",
    "                os.path.join(csvdir, fname),\n",
    "                parse_dates=[0],\n",
    "                index_col=0,\n",
    "            ).sort_index()\n",
    "\n",
    "            start_date = dfr.index[0]\n",
    "            end_date = dfr.index[-1]\n",
    "            # The auto_close date is the day after the last trade.\n",
    "            ac_date = end_date + pd.Timedelta(days=1)\n",
    "            metadata.iloc[sid] = start_date, end_date, ac_date, symbol\n",
    "            print(\"mayank::start_date\", start_date)\n",
    "            print(\"mayank::end_date\", end_date)\n",
    "            if \"split\" in dfr.columns:\n",
    "                tmp = 1.0 / dfr[dfr[\"split\"] != 1.0][\"split\"]\n",
    "                split = pd.DataFrame(\n",
    "                    data=tmp.index.tolist(), columns=[\"effective_date\"]\n",
    "                )\n",
    "                split[\"ratio\"] = tmp.tolist()\n",
    "                split[\"sid\"] = sid\n",
    "\n",
    "                splits = divs_splits[\"splits\"]\n",
    "                index = pd.Index(\n",
    "                    range(splits.shape[0], splits.shape[0] + split.shape[0])\n",
    "                )\n",
    "                split.set_index(index, inplace=True)\n",
    "                divs_splits[\"splits\"] = pd.concat([splits, split], axis=0)\n",
    "\n",
    "            if \"dividend\" in dfr.columns:\n",
    "                # ex_date   amount  sid record_date declared_date pay_date\n",
    "                tmp = dfr[dfr[\"dividend\"] != 0.0][\"dividend\"]\n",
    "                div = pd.DataFrame(data=tmp.index.tolist(), columns=[\"ex_date\"])\n",
    "                div[\"record_date\"] = pd.NaT\n",
    "                div[\"declared_date\"] = pd.NaT\n",
    "                div[\"pay_date\"] = pd.NaT\n",
    "                div[\"amount\"] = tmp.tolist()\n",
    "                div[\"sid\"] = sid\n",
    "\n",
    "                divs = divs_splits[\"divs\"]\n",
    "                ind = pd.Index(range(divs.shape[0], divs.shape[0] + div.shape[0]))\n",
    "                div.set_index(ind, inplace=True)\n",
    "                divs_splits[\"divs\"] = pd.concat([divs, div], axis=0)\n",
    "\n",
    "            yield sid, dfr\n",
    "\n",
    "\n",
    "#register_calendar_alias(\"CSVDIR\", \"NYSE\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
